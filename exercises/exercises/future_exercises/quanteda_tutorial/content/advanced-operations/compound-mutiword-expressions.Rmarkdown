---
title: Compound multi-word expressions
weight: 20
draft: false
---

We can compound multi-word expressions through collocation analysis. In this example, we will identify sequences of capitalized words and compound them as proper names, which are important linguistic features of newspaper articles.

```{r message=FALSE}
require(quanteda)
require(quanteda.textstats)
require(quanteda.corpora)
options(width = 110)
```

This corpus contains 6,000 Guardian news articles from 2012 to 2016.

```{r eval=FALSE}
corp_news <- download("data_corpus_guardian")
```

```{r include=FALSE}
# This code is only for website generation
corp_news <- readRDS("../data/data_corpus_guardian.rds")
```

```{r}
```

We remove punctuation marks and symbols in `tokens()` and stopwords in `tokens_remove()` with `padding = TRUE` to keep the original positions of tokens. 

```{r}
toks_news <- tokens(corp_news, remove_punct = TRUE, remove_symbols = TRUE, padding = TRUE) %>% 
    tokens_remove(stopwords("en"), padding = TRUE)
```

One of the most common type of multi-word expressions is proper names, which we can select simply based on capitalization in English texts.

```{r}
toks_news_cap <- tokens_select(toks_news, 
                               pattern = "^[A-Z]",
                               valuetype = "regex",
                               case_insensitive = FALSE, 
                               padding = TRUE)

tstat_col_cap <- textstat_collocations(toks_news_cap, min_count = 10, tolower = FALSE)
head(tstat_col_cap, 20)
```

We will only compound strongly associated multi-word expressions here by subsetting `tstat_col_cap` with the z-score (`z > 3`).

```{r}
toks_comp <- tokens_compound(toks_news, pattern = tstat_col_cap[tstat_col_cap$z > 3,], 
                             case_insensitive = FALSE)
kw_comp <- kwic(toks_comp, pattern = c("London_*", "British_*"))
head(kw_comp, 10)
```
