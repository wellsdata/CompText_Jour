---
title: Collocation analysis
weight: 50
chapter: false
draft: false
---

```{r message=FALSE}
require(quanteda)
require(quanteda.textstats)
require(quanteda.corpora)
```

This corpus contains 6,000 Guardian news articles from 2012 to 2016.

```{r eval=FALSE}
corp_news <- download("data_corpus_guardian")
```

```{r include=FALSE}
# This code is only for website generation
corp_news <- readRDS("../data/data_corpus_guardian.rds")
```


A collocation analysis allows us to identify contiguous collocations of words. One of the most common types of multi-word expressions are proper names, which can be identified simply based on capitalization in English texts.

```{r}
toks_news <- tokens(corp_news, remove_punct = TRUE)
tstat_col_caps <- tokens_select(toks_news, pattern = "^[A-Z]", 
                                valuetype = "regex", 
                                case_insensitive = FALSE, 
                                padding = TRUE) %>% 
                  textstat_collocations(min_count = 100)
head(tstat_col_caps, 20)
```

You can also discover collocations longer than two words. In the example below we identify collocations consisting of three words.

```{r}
tstat_col2 <- tokens_select(toks_news, pattern = "^[A-Z]", 
                                valuetype = "regex", 
                                case_insensitive = FALSE, 
                                padding = TRUE) %>% 
              textstat_collocations(min_count = 100, size = 3)
head(tstat_col2, 20)
```

{{% notice tip %}}
If you find `textstat_collocations()` is taking too much time, increase the `min_count` threshold to speed up the estimation. You also do not need to set `sizes` larger than 2 to compound multi-word expressions, because overlapped collocations are chained if `join = TRUE` in `tokens_compound()`.
{{% /notice %}}
