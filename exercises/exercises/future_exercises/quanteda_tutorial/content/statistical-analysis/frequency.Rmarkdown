---
title: Simple frequency analysis
weight: 10
chapter: false
draft: false
---

```{r message=FALSE}
require(quanteda)
require(quanteda.textstats)
require(quanteda.textplots)
require(quanteda.corpora)
require(ggplot2)
```

Unlike `topfeatures()`, `textstat_frequency()` shows both term and document frequencies. You can also use the function to find the most frequent features within groups.

Using the `download()` function from **quanteda.corpora**, you can retrieve a text corpus of tweets.

```{r eval=FALSE}
corp_tweets <- download(url = "https://www.dropbox.com/s/846skn1i5elbnd2/data_corpus_sampletweets.rds?dl=1")
```

```{r include=FALSE}
# This code is only for website generation
corp_tweets <- readRDS("../data/data_corpus_sampletweets.rds")
```

We can analyse the most frequent hashtags by applying `tokens_keep(pattern = "#*")` before creating a DFM.

```{r}
toks_tweets <- tokens(corp_tweets, remove_punct = TRUE) %>% 
               tokens_keep(pattern = "#*")
dfmat_tweets <- dfm(toks_tweets)

tstat_freq <- textstat_frequency(dfmat_tweets, n = 5, groups = lang)
head(tstat_freq, 20)
```

You can also plot the Twitter hashtag frequencies easily using `ggplot()`.

```{r}
dfmat_tweets %>% 
  textstat_frequency(n = 15) %>% 
  ggplot(aes(x = reorder(feature, frequency), y = frequency)) +
  geom_point() +
  coord_flip() +
  labs(x = NULL, y = "Frequency") +
  theme_minimal()
```

Alternatively, you can create a word cloud of the 100 most common hashtags.

```{r, height = 8, width = 8}
set.seed(132)
textplot_wordcloud(dfmat_tweets, max_words = 100)
```

Finally, it is possible to compare different groups within one Wordcloud. We must first create a dummy variable that indicates whether a tweet was posted in English or a different language. Afterwards, we can compare the most frequent hashtags of English and non-English tweets.

```{r message=FALSE, warning=FALSE, height=8, width=8}
# create document-level variable indicating whether tweet was in English or other language
corp_tweets$dummy_english <- factor(ifelse(corp_tweets$lang == "English", "English", "Not English"))

# tokenize texts
toks_tweets <- tokens(corp_tweets)

# create a grouped dfm and compare groups
dfmat_corp_language <- dfm(toks_tweets) %>% 
                       dfm_keep(pattern = "#*") %>% 
                       dfm_group(groups = dummy_english)

# create wordcloud
set.seed(132) # set seed for reproducibility
textplot_wordcloud(dfmat_corp_language, comparison = TRUE, max_words = 200)
```

