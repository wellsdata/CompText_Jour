---
title: Generate n-grams
weight: 60
draft: false
---

```{r message=FALSE}
require(quanteda)
options(width = 110)
```

```{r}
toks <- tokens(data_char_ukimmig2010, remove_punct = TRUE)
```

You can generate n-grams in any lengths from a tokens using `tokens_ngrams()`. N-grams are a sequence of tokens from already tokenized text objects.

```{r}
toks_ngram <- tokens_ngrams(toks, n = 2:4)
head(toks_ngram[[1]], 30)
tail(toks_ngram[[1]], 30)
```

`tokens_ngrams()` also supports skip to generate skip-grams.

```{r}
toks_skip <- tokens_ngrams(toks, n = 2, skip = 1:2)
head(toks_skip[[1]], 30)
```

## Selective ngrams

While `tokens_ngrams()` generates n-grams or skip-grams in all possible combinations of tokens, `tokens_compound()` generates n-grams more selectively. For example, you can make negation bi-grams using `phrase()` and a wild card (`*`).

```{r}
toks_neg_bigram <- tokens_compound(toks, pattern = phrase("not *"))
toks_neg_bigram_select <- tokens_select(toks_neg_bigram, pattern = phrase("not_*"))
head(toks_neg_bigram_select[[1]], 30)
```

{{% notice tip %}}
`tokens_ngrams()` is an efficient function, but it returns a large object if multiple values are given to `n` or `skip`. Since n-grams inflates the size of objects without adding much information, we recommend generating n-grams more selectively using `tokens_compound()`.
{{% /notice %}}
