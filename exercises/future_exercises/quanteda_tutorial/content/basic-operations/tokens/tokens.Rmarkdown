---
title: Construct a tokens object
weight: 10
draft: false
---

```{r message=FALSE}
require(quanteda)
options(width = 110)
```

`tokens()` segments texts in a corpus into tokens (words or sentences) by word boundaries. 

```{r}
corp_immig <- corpus(data_char_ukimmig2010)
toks_immig <- tokens(corp_immig)
```

{{% notice tip %}}
`tokens()` can tokenize texts in Asian languages such as Japanese or Chinese without additional tools thanks to the **stringi** package. See an example of in [documentation website](https://quanteda.io/articles/pkgdown/examples/chinese.html).
{{% /notice %}}

By default, `tokens()` only removes separators (typically white spaces), but you can also remove punctuation and numbers.

```{r}
toks_nopunct <- tokens(data_char_ukimmig2010, remove_punct = TRUE)
print(toks_nopunct)
```

