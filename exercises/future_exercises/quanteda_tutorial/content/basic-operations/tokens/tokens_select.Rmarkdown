---
title: Select tokens
weight: 30
draft: false
---

```{r message=FALSE}
require(quanteda)
options(width = 110)
```

```{r}
toks <- tokens(data_char_ukimmig2010)
```

You can remove tokens that you are not interested in using `tokens_select()`. Usually we remove function words (grammatical words) that have little or no substantive meaning in pre-processing. `stopwords()` returns a pre-defined list of function words.

```{r}
toks_nostop <- tokens_select(toks, pattern = stopwords("en"), selection = "remove")
print(toks_nostop)
```

`tokens_remove()` is an alias to `tokens_select(selection = "remove")`. Therefore, the code above and below are equivalent.

```{r}
toks_nostop2 <- tokens_remove(toks, pattern = stopwords("en"))
print(toks_nostop2)
```

Removal of tokens changes the lengths of documents, but they remain the same if you set `padding = TRUE`. This option is useful especially when you perform positional analysis.

```{r}
toks_nostop_pad <- tokens_remove(toks, pattern = stopwords("en"), padding = TRUE)
print(toks_nostop_pad)
```

If you are only interested in certain words, you can keep these and remove others.

```{r}
toks_immig <- tokens_select(toks, pattern = c("immig*", "migra*"), padding = TRUE)
print(toks_immig)
```

If you want to analyze words that appear around keywords, use the `window` argument.

```{r}
toks_immig_window <- tokens_select(toks, pattern = c("immig*", "migra*"), padding = TRUE, window = 5)
print(toks_immig_window)
```

{{% notice tip %}}
We keep using *glob* patterns in this tutorials, but almost all the functions in **quanteda** support *regular expression* patterns. See `?pattern` for details and this [cheatsheet](https://www.cheatography.com/davechild/cheat-sheets/regular-expressions/pdf_bw/) for a concise introduction to frequently used regular expressions.
{{% /notice %}}

