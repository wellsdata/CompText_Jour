knitr::opts_chunk$set(echo = TRUE)
#KEY
md_race <- read_csv("lab_03.csv")
library(tidyverse)
library(janitor)
#KEY
md_race <- read_csv("lab_03.csv")
md_race <- read_csv("/Users/robwells/Code/data_journalism_class/04_labs/lab_03/lab_03.csv")
md_race %>%
select(place,x2020_hispanic,x2010_hispanic,x2020_total) %>%
slice_max(x2020_hispanic,n=15)
knitr::opts_chunk$set(echo = TRUE)
here::here("/Code/data_journalism_class/04_labs/lab_04")
# Turn off scientific notation
options(scipen=999)
# Load the tidyverse here
# Load janitor here
#KEY
library(tidyverse)
library(janitor)
# Write code to load the Maryland race by city, place for 2010 - 2020 and call it md_race.
# The data is called lab_04.csv, and is in the same folder as lab_04.qmd (this data notebook)
#KEY
library(here)
here::here("/Code/data_journalism_interactive_textbook/04_labs/lab_04")
md_race <- read_csv(here::here("~/Code/data_journalism_class/04_labs/lab_04/lab_04.csv"))
# Write your code in this codeblock.
#KEY
top5_hispanic_pct <- md_race %>%
select(place, x2020_total, x2020_hispanic) %>%
mutate(pct_hispanic = (x2020_hispanic/x2020_total)) %>%
slice_max(pct_hispanic, n =5)
top5_hispanic_pct
#write your code here
#KEY
pct_black <- md_race %>%
select(place, x2020_black, x2020_total, x2010_black, x2010_total) %>%
filter(x2010_total > 20000) %>%
mutate(pct_black_2020 = (x2020_black/x2020_total)) %>%
mutate(pct_black_2010 = (x2010_black/x2010_total)) %>%
select(place, pct_black_2020, pct_black_2010, x2020_black, x2020_total, x2010_black, x2010_total) %>%
slice_max(pct_black_2020, n = 10)
pct_black
# KEY
hisp_growth <- md_race %>%
select(place, x2020_hispanic, x2020_total, x2010_hispanic, x2010_total) %>%
filter(x2020_total > 10000) %>%
mutate(hispanic_growth = ((x2020_hispanic-x2010_hispanic)/x2010_hispanic)*100) %>%
mutate(total_growth = ((x2020_total-x2010_total)/x2010_total)*100) %>%
select(place,hispanic_growth, total_growth, x2020_hispanic, x2020_total, x2010_hispanic, x2010_total) %>%
slice_max(hispanic_growth, n = 15)
hisp_growth
hisp_growth <- md_race %>%
select(place, x2020_hispanic, x2020_total, x2010_hispanic, x2010_total) %>%
filter(x2020_total > 10000) %>%
mutate(hisp_change = (x2020_hispanic - x2010_hispanic)/x2010_hispanic * 100,
total_change = (x2020_total - x2010_total)/x2010_total * 100) %>%
arrange(desc(hisp_change))
View(hisp_growth)
library(formattable)
#then calculate percent change for top 5 cities with highest Hispanic pops. and create a new table
top5_hispanic <- md_race %>%
select(place, x2020_hispanic, x2020_total) %>%
mutate(pct_total_hispanic = percent(x2020_hispanic/x2020_total)) %>%
slice_max(pct_total_hispanic, n = 5)
View(top5_hispanic)
top5_hispanic <- md_race %>%
select(place,x2020_hispanic,x2020_total) %>%
mutate(ratio_h=((x2020_hispanic/x2020_total)*100)) %>%
arrange(desc(ratio_h)) %>%
slice_head(n = 5)
View(top5_hispanic)
baltcity_income<- read_csv("assets/data/baltcity_income_clean.csv") %>%
as.data.frame()
baltcity_income<- read_csv("/Users/robwells/Library/CloudStorage/GoogleDrive-robwells@umd.edu/My Drive/Data Spring 2024/Storage Spring 2024 Data/data_journalism_interactive_textbook/04_labs/lab_05/pre_lab_05/baltcity_income_clean.csv") %>%
as.data.frame()
summary(baltcity_income$x2020)
baltcity_income<- read_csv("/Users/robwells/Library/CloudStorage/GoogleDrive-robwells@umd.edu/My Drive/Data Spring 2024/Storage Spring 2024 Data/data_journalism_interactive_textbook/04_labs/lab_05/pre_lab_05/baltcity_income_clean.csv") %>%
as.data.frame()
summary(baltcity_income$x2020)
top <- baltcity_income %>%
select(Census, x2020) %>%
filter(x2020 > 56311) %>%
count()
#There were 97 census tracts above the citywide median income of $49875
bottom <- baltcity_income %>%
select(Census, x2020) %>%
filter(x2020 < 56311) %>%
count()
View(top)
View(bottom)
answer <- (bottom/200)
answer
View(answer)
knitr::opts_chunk$set(echo = TRUE)
here::here("/Code/data_journalism_class/04_labs/lab_05")
# Turn off scientific notation
options(scipen=999)
#KEY
library(tidyverse)
library(janitor)
here::here("/Code/data_journalism_class/04_labs/lab_05")
us_death <- read_csv(here::here("~/Code/data_journalism_class/04_labs/lab_05/CDC_Life_Census_Tract_2010_2015.csv"))
us_death <- janitor::clean_names(us_death)
nrow(us_death)
#73121
names(us_death)
#
md_death <- us_death %>%
filter(state == "Maryland")
nrow(md_death)
#1407
balt_death <- md_death %>%
filter(county == "Baltimore city, MD")
nrow(balt_death)
#200
#KEY
balt_death2 <- read_csv(here::here("~/Code/data_journalism_class/04_labs/lab_05/balt_death_census.csv"))
summary(balt_death2$life_expectancy, na.m=TRUE)
#Show in New Window
#  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
# 62.60   69.58   72.70   73.04   76.03   87.30      20
balt_death2 %>%
select(neighborhood, life_expectancy) %>%
filter(life_expectancy <= 69.58) %>%
arrange(life_expectancy)
#KEY
balt_death2 <- read_csv(here::here("~/Code/data_journalism_class/04_labs/lab_05/balt_death_census.csv"))
summary(balt_death2$life_expectancy, na.m=TRUE)
#Show in New Window
#  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
# 62.60   69.58   72.70   73.04   76.03   87.30      20
balt_death2 %>%
select(neighborhood, life_expectancy) %>%
filter(life_expectancy <= 69.58) %>%
arrange(life_expectancy)
#KEY
balt_death <- balt_death %>%
mutate(
above_below_avg = case_when(
life_expectancy >= '72.7' ~ "Above",
life_expectancy <= '72.7' ~ "Below"
)
balt_death %>%
count(above_below_avg)
knitr::opts_chunk$set(echo = TRUE)
here::here("/Code/data_journalism_class/04_labs/lab_05/pre_lab_05/")
mdcities <- read_csv(here::here("~/Code/data_journalism_class/04_labs/lab_05/pre_lab_05/city_md_income.csv")) %>%
as.data.frame()
mdcities <- mdcities %>%
mutate(income_diff = (median_inc_2020-median_inc_2010)) %>%
mutate(income_pct_chg = round((median_inc_2020-median_inc_2010)/median_inc_2010*100,2))
View(mdcities)
summary(mdcities)
summary(mdcities$median_inc_2020)
lowest <- mdcities %>%
mutate(
category = case_when(
median_inc_2020 <= `63327` ~ "lowest",
median_inc_2020 >= `63327` ~ "above"
)
lowest <- mdcities %>%
mutate(
category = case_when(
median_inc_2020 <= "63327" ~ "lowest",
median_inc_2020 >= "63327" ~ "above"
)
View(lowest)
library(quarto)
quarto::quarto_render()
setwd("~/Code/data_journalism_class/03_tutorials/qmd_files")
library(quarto)
quarto::quarto_render()
library(tidyverse)
###
# Total population for each Maryland county
# County identified by GEOID (a 5-digit code), not name
###
maryland_county_population <- read_rds("assets/data/maryland_county_population.rds")
###
# A lookup table that shows the name of each Maryland county, paired with GEOID
###
maryland_county_lookup_table <- read_rds("assets/data/maryland_county_lookup_table.rds")
###
# Total population for each Maryland county, EXCEPT for Prince George's County
# County identified by GEOID (a 5-digit code), not name
###
maryland_county_population_no_pg <- read_rds("assets/data/maryland_county_population_no_pg.rds")
###
# Display the tables
###
maryland_county_population
maryland_county_lookup_table
maryland_county_population_no_pg
updated_maryland_county_population <- maryland_county_lookup_table %>%
inner_join(maryland_county_population, by="geoid")
updated_maryland_county_population
updated_maryland_county_population_no_pg <- maryland_county_lookup_table %>%
inner_join(maryland_county_population_no_pg, by="geoid")
updated_maryland_county_population_no_pg
if (knitr::is_html_output())
knitr::include_graphics("assets/inner-join.gif")
# ![inner join](assets/inner-join.gif){width="100%"}
updated_maryland_county_population_no_pg <- maryland_county_lookup_table %>%
left_join(maryland_county_population_no_pg, by="geoid")
updated_maryland_county_population_no_pg
View(maryland_county_population)
View(maryland_county_lookup_table)
View(maryland_county_population)
maryland_tracts <- rio::import("maryland_tracts.xls")
md_counties_goeids <- rio::import("md_counties_goeids.txt")
md_counties_geoids <- rio::import("md_counties_geoids.txt")
names(md_counties_geoids)
names(maryland_tracts)
View(maryland_tracts)
md_smith_data <- maryland_tracts %>%
inner_join(md_counties_geoids, by=("cty"="GEOID"))
md_smith_data <- maryland_tracts %>%
inner_join(md_counties_geoids, by=c("cty"="GEOID"))
View(md_smith_data)
census <- md_smith_data %>%
select(NAME, census_response_rate2020) %>%
summarize(average = mean(census_response_rate2020)) %>%
arrange(desc(average))
View(census)
census <- md_smith_data %>%
select(NAME, census_response_rate2020) %>%
summarize(average = mean(census_response_rate2020, na.rm = TRUE)) %>%
arrange(desc(average))
census <- md_smith_data %>%
select(NAME, census_response_rate2020) %>%
group_by(NAME) %>%
summarize(average = mean(census_response_rate2020, na.rm = TRUE)) %>%
arrange(desc(average))
View(census)
quarto::quarto_render(input = "index.qmd", output_file = "index.html")
library(tidyverse)
library(textdata)
library(tidytext)
library(quanteda)
library(rio)
#import df created from sequence below
black <- read.csv("../data/black_press_extracted_text_june_22_2024.csv")
getwd()
black <- read.csv("../CompText_Jour/data/black_press_extracted_text_june_22_2024.csv")
black <- read.csv("~/Code/CompText_Jour/data")
black <- read.csv("~/Code/CompText_Jour/data/black_press_extracted_text_june_22_2024.csv")
#import df created from sequence below
black <- read.csv("~/Code/CompText_Jour/data/black_press_extracted_text_june_22_2024.csv")
all_text <- str_replace_all(black$sentence, "- ", "")
text_df <- tibble(all_text,)
# unnest includes lower, punct removal
text_tokenized <- text_df %>%
unnest_tokens(word,all_text)
text_tokenized
#Remove stopwords
data(stop_words)
text_tokenized<- text_tokenized %>%
anti_join(stop_words, by = c("word" = "word")) %>%
filter(word != "temp_file") %>%
#NOT SURE IF THIS LINE SHOULD REMAIN
filter(word != "stories_corpus") %>%
filter(!grepl('[0-9]', word))
# fix the script so it doesn't pick up these file names, numbers
# forcibly removing for now
# Word Count
text_word_ct <- text_tokenized %>%
count(word, sort=TRUE)
# cite this lexicon
#install.packages("textdata")
nrc_sentiments <- get_sentiments("nrc")
afinn_sentiments <- get_sentiments("afinn")
nrc_sentiments %>% count(sentiment)
#sentiment & count
# anger	1246
# anticipation	837
# disgust	1056
# fear	1474
# joy	687
# negative	3318
# positive	2308
# sadness	1187
# surprise	532
# trust	1230
nrc_sentiments %>%
group_by(word) %>%
count() %>%
arrange(desc(n)) %>%
distinct()
nrc_sentiments %>%
group_by(word) %>%
count() %>%
arrange(desc(n)) %>%
distinct()
sentiments_all <- text_tokenized %>%
inner_join(nrc_sentiments)
#this dictionary assigns different values to the same word. negro is negative, sadness whereas lynch is anger, disgust, fear, negative and sadness.
x <- sentiments_all %>%
group_by(word) %>%
count(sentiment)
View(x)
sentiments_all <- text_tokenized %>%
inner_join(nrc_sentiments) %>%
count(sentiment, sort = TRUE) %>%
mutate(pct_total =round(n/sum(n), digits=2))
sentiments_all
library(ggplot2)
afinn_plot <- ggplot(sentiments_all,aes(x = sentiment, y = n,fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
labs(title = "Total Sentiment in Black Press Lynching News Coverage",
subtitle = " ",
caption = "NRC Sentiment analysis. Graphic by Rob Wells, 8-25-2024",
y="Score",
x="total sentiment score")
afinn_plot + scico::scale_fill_scico(palette = "vik")
# ggsave("Figure5_afinn_sentiment_jan2.png",device = "png",width=9,height=6, dpi=800)
# Anger
nrc_anger <- nrc_sentiments %>%
filter(sentiment == "anger")
lynching_anger <- text_tokenized %>%
inner_join(nrc_anger) %>%
count(word, sort = TRUE)
lynching_anger
# Anticipation
# results / themes not as clear as anger
nrc_anticipation <- nrc_sentiments %>%
filter(sentiment == "anticipation")
lynching_anticipation <- lynching_tokenized %>%
inner_join(nrc_anticipation) %>%
count(word, sort = TRUE)
# Anticipation
# results / themes not as clear as anger
nrc_anticipation <- nrc_sentiments %>%
filter(sentiment == "anticipation")
lynching_anticipation <- text_tokenized %>%
inner_join(nrc_anticipation) %>%
count(word, sort = TRUE)
lynching_anticipation
# Fear
# see a reflection of the basic word count in these results
nrc_fear <- nrc_sentiments %>%
filter(sentiment == "fear")
lynching_fear <- text_tokenized %>%
inner_join(nrc_fear) %>%
count(word, sort = TRUE)
lynching_fear
# Disgust
# see a reflection of the basic word count in these results
nrc_disgust <- nrc_sentiments %>%
filter(sentiment == "disgust")
lynching_disgust <- text_tokenized %>%
inner_join(nrc_disgust) %>%
count(word, sort = TRUE)
lynching_disgust
text_500 <- text_word_ct %>%
filter(n >= 29)
View(text_500)
custom_dictionary <- text_500 %>%
inner_join(nrc_sentiments)
View(custom_dictionary)
knitr::opts_chunk$set(echo = TRUE)
system("brew install tesseract")
system("brew install xpdf")
system("xcode-select --install")
system("brew install libtiff")
system("brew install ghostscript")
system("brew install imagemagick")
system("pdftotext /Users/robwells/Code/misc_notes/notes/Manafort_filing.pdf name-of-my-text-file.txt")
# For tabular data
system("pdftotext -table /Users/robwells/Code/misc_notes/notes/07012018-report-final.pdf tabular-test1.txt")
library(fs)
# Set paths
pdf_folder <- "/Users/robwells/Code/misc_notes/pdfs"
extracted_folder <- "/Users/robwells/Code/misc_notes/extracted"
# Create the extracted folder if it doesn't exist
if (!dir_exists(extracted_folder)) {
dir_create(extracted_folder)
}
# Get list of PDF files
pdf_files <- dir_ls(pdf_folder, glob = "*.pdf")
# Process each PDF file
for (pdf_file in pdf_files) {
output_file <- path(extracted_folder, path_ext_set(path_file(pdf_file), "txt"))
system2("pdftotext", args = c(pdf_file, output_file))
cat("Text extracted from", path_file(pdf_file), "and saved to", path_file(output_file), "\n")
}
# Install tesseract if not already installed
system("brew install tesseract")
# Convert PNG to searchable PDF
system("tesseract /Users/robwells/Code/misc_notes/pdfs/'a lynching in ohio.png' out.pdf")
# Convert the searchable PDF to text
system("pdftotext out.pdf out.txt")
