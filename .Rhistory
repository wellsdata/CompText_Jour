# Append the parsed line to the data frame if it contains valid data
if (!is.na(parsed_line$title) && !is.na(parsed_line$date) && !is.na(parsed_line$volume)) {
df <- bind_rows(df, parsed_line)
}
write.csv(df, "df_index.csv")
index <- c("
At work on book on New Deal; pic. N 15: 21;
LBJ, JFK & Route 66. Jl 5: 88;
Meaning of the Fair. Jl 12: 92;
The Bracero Blunder. Jl 19: 88;
What a Party Can‘t Do. Jl 26: 96;
Exporting Communism. Ag 2: 72;
The Power Narcotic. Ag 9: 84;
The Fortas Appointment. Ag 16: 84;
The Withered Arm-1. Ag 23: 84;
The Withered Arm-II. Ag 30: 84;
Jefferson Davis. S 6: 72;
The House of Law. S 13: 96;
The Establishment. S 20: 104;
Profits From Subsidies. S 27: 112;
The Ill-Kept City. O 4: 106;
Laws. Then What Next? O 11: 116;
Tax Help for Parents. O 18: 132;
Inefficient Colleges. O 25: 124;
The Morrissey Case. N 1: 100;
Sorensen’s Kennedy. N 8: 120;
The Way to Resume. D 13: 112;
A Brief, Not a History. D 20: 108;
Freedom of the Seas. D 27: 74;")
# Split the index string into individual lines
index_lines <- str_split(index, ";\\s*")[[1]]
# Initialize an empty data frame with consistent data types
df <- data.frame(year = character(), title = character(), date = character(), volume = numeric(), stringsAsFactors = FALSE)
# Define a function to parse a line
parse_line <- function(line) {
# Extract the title
title <- str_trim(str_extract(line, "^[^\\.]+"))
# Extract the date and volume
date_volume <- str_extract(line, "[A-Za-z]+\\s[0-9]+:\\s*[0-9]+")
date <- str_trim(str_extract(date_volume, "^[A-Za-z]+\\s[0-9]+"))
volume <- as.numeric(str_extract(date_volume, "[0-9]+$"))
year <- "1965"
return(data.frame(year = year, title = title, date = date, volume = volume, stringsAsFactors = FALSE))
}
# Parse each line and append to the data frame
for (line in index_lines) {
# Only process non-empty lines
if (nchar(line) > 0 && !is.na(line)) {
parsed_line <- parse_line(line)
# Append the parsed line to the data frame if it contains valid data
if (!is.na(parsed_line$title) && !is.na(parsed_line$date) && !is.na(parsed_line$volume)) {
df <- bind_rows(df, parsed_line)
}
write.csv(df, "df_index.csv")
index <- c("
Blockade Saves Lives Ja 3:60;
U.S. Patent Policy Ja 10: 68;
Why a Subsidy? Ja17: 88;
Automotive Safety I-V Ja 24: 92;
Automotive Safety Ja 31:80;
Automotive Safety F 7: 88;
Automotive Safety F 14: 100;
Automotive Safety F 21: 106;
Guns and Butter Plus F 28: 96;
Politics and Police Mr 7: 104;
Pragmatic Republican Mr 14: 108;
LBJ and Auto Safety Mr 21: 112;
Political Education Mr 28: 108;
-Innocent Bystander Ap 4: 104;
Mendicant Cities Ap 11: 116;
Below Hell's Canyon Ap 18: 116;
High Mountain Sheep Ap 25: 96;
Alabama in Tronsition My 2: 108;
The GOP in the South My 9: 108;
The Ordeal of Djilas My 16: 124;
The Auto Safety Dispute My 23: 124;
Another Co-op Crutch My 30: 98;
Corporate Giving I-III Je 6: 104;
Corporate Giving Je 13: 124;
Corporate Giving Je 20: 112;
After the Primary Je 27: 98;
Struggle For The Land Jl 4: 92;
Property Tax Reform J 1 11: 96;
ahan's Long Shadow Jl 18: 100;
East of Suez JI 2S: 96;
Interstate Highways Ag 1: 88;
Pattern of Revolution Ag 8: 84;
The Uses of Power Ag 15: 92;
The Cold Wet War Ag 22: l 04;
An Old Wives Tale Ag 29: 76;
The Worth of a Name O 10: 124;
For a Better Congress O 17: 114;
A Pro's-Eye View O 24: 126;
Rockefeller O 31: 120;
A Vote of Confidence N 7: 116;
Paying for Politics N 14: 116;
Liberty and Discipline N 21: 136;
Semantic Tyranny N 28: 120;
The 25 GOP Governors D 5: 11;
State Self-Supp D 12: 116;
Political Unions Woe D 19: 120;
Governors to the Front D 26: 76;
")
# Split the index string into individual lines
index_lines <- str_split(index, ";\\s*")[[1]]
# Initialize an empty data frame with consistent data types
df <- data.frame(year = character(), title = character(), date = character(), volume = numeric(), stringsAsFactors = FALSE)
# Define a function to parse a line
parse_line <- function(line) {
# Extract the title
title <- str_trim(str_extract(line, "^[^\\.]+"))
# Extract the date and volume
date_volume <- str_extract(line, "[A-Za-z]+\\s[0-9]+:\\s*[0-9]+")
date <- str_trim(str_extract(date_volume, "^[A-Za-z]+\\s[0-9]+"))
volume <- as.numeric(str_extract(date_volume, "[0-9]+$"))
year <- "1966"
return(data.frame(year = year, title = title, date = date, volume = volume, stringsAsFactors = FALSE))
}
# Parse each line and append to the data frame
for (line in index_lines) {
# Only process non-empty lines
if (nchar(line) > 0 && !is.na(line)) {
parsed_line <- parse_line(line)
# Append the parsed line to the data frame if it contains valid data
if (!is.na(parsed_line$title) && !is.na(parsed_line$date) && !is.na(parsed_line$volume)) {
df <- bind_rows(df, parsed_line)
}
write.csv(df, "df_index.csv")
index <- c("
Taxation as Discipline Ja 2: 68;
Coordinating the GOP Ja 9: 72;
It was No Monolith J 23: 104;
Unfair Tax-Rates: F 6: 108;
Wilson, Bullitt, Freud F 20: 104;
Creative Federalism Mr 6. 100;
Free for Whom? Mr 20: 112;
Wallace Threat Ap 3: 100;
Campaign Agonies Ap 17: 120;
Mr O'Briens Leviathan My 1: 96;
A New Electric Age My 15: 108;
The Battleship Returns My 29: 104;
The US, UN and UK Je 12: 104;
Ass in Lions Skin Je 26: 80;
Titan Unbound, I Jl 24: 80;
Tit Unbound, II Ag 7: 84;
What Kind of City? Ag 21: 72;
Rockfeller-Reagan S 18: 112;
Subsidy or Windfall O 2: 100;
Those Alleged Postal Subsidies O 16: 112;
Portrait of the GOP O 30: 108;
The GOP Mainstream N 13: 126;
A Look Beyond the War N 27: 108;
Romney the Incredible D 11: 116;
A Personal Note, Last column for Newsweek D 25: 76;
")
# Split the index string into individual lines
index_lines <- str_split(index, ";\\s*")[[1]]
# Initialize an empty data frame with consistent data types
df <- data.frame(year = character(), title = character(), date = character(), volume = numeric(), stringsAsFactors = FALSE)
# Define a function to parse a line
parse_line <- function(line) {
# Extract the title
title <- str_trim(str_extract(line, "^[^\\.]+"))
# Extract the date and volume
date_volume <- str_extract(line, "[A-Za-z]+\\s[0-9]+:\\s*[0-9]+")
date <- str_trim(str_extract(date_volume, "^[A-Za-z]+\\s[0-9]+"))
volume <- as.numeric(str_extract(date_volume, "[0-9]+$"))
year <- "1967"
return(data.frame(year = year, title = title, date = date, volume = volume, stringsAsFactors = FALSE))
}
# Parse each line and append to the data frame
for (line in index_lines) {
# Only process non-empty lines
if (nchar(line) > 0 && !is.na(line)) {
parsed_line <- parse_line(line)
# Append the parsed line to the data frame if it contains valid data
if (!is.na(parsed_line$title) && !is.na(parsed_line$date) && !is.na(parsed_line$volume)) {
df <- bind_rows(df, parsed_line)
}
write.csv(df, "df_index.csv")
library(tidyverse)
mob <- read.csv("~/Code/CompText_Jour/data/mob_analysis_data.csv")
dim(mob)
ncol(mob)
nrow(mob)
dim(mob)
names(mob)
mob %>%
count(Newspaper) %>%
arrange(desc(n))
mob %>%
count(keyword) %>%
arrange(desc(n))
mob %>%
count(Year) %>%
arrange(desc(n))
years <- mob %>%
count(Year) %>%
arrange(desc(n))
View(years)
years <- mob %>%
count(Year) %>%
arrange(desc(Year))
View(years)
years <- mob %>%
count(Year) %>%
arrange(Year)
View(years)
ggplot(data=years) +
geom_col(mapping=aes(x=Year, y=n))
# Step 1: Read the entire text file into R
file_path <- "/Users/robwells/Desktop/split_file/kemi.txt"
text_data <- readLines(file_path)
# Step 1: Read the entire text file into R
file_path <- "../Desktop/split_file/kemi.txt"
text_data <- readLines(file_path)
file_path <- "../split_file/kemi.txt"
text_data <- readLines(file_path)
getwd()
setwd("~/Code/CompText_Jour")
getwd()
file_path <- "/CompText_Jour/code/split_file/kemi.txt"
text_data <- readLines(file_path)
file_path <- "../CompText_Jour/code/split_file/kemi.txt"
text_data <- readLines(file_path)
# Step 1: Read the entire text file into R
file_path <- "../CompText_Jour/code/split_file/kemi.txt"
text_data <- readLines(file_path)
# Step 2: Combine lines into one single string
text_combined <- paste(text_data, collapse = "\n")
# Step 3: Split the text by the "End of Document" phrase
documents <- strsplit(text_combined, "End of Document")[[1]]
# Step 4: Write each section to a new file
output_dir <- "/Users/robwells/Desktop/split_file/"
for (i in seq_along(documents)) {
output_file <- file.path(output_dir, paste0("document_", i, ".txt"))
writeLines(documents[[i]], output_file)
}
# Step 1: Read the entire text file into R
file_path <- "../CompText_Jour/code/split_file/kemi.txt"
text_data <- readLines(file_path)
# Step 2: Combine lines into one single string
text_combined <- paste(text_data, collapse = "\n")
# Step 3: Split the text by the "End of Document" phrase
documents <- strsplit(text_combined, "End of Document")[[1]]
# Step 4: Write each section to a new file
output_dir <- "../CompText_Jour/code/split_file/"
for (i in seq_along(documents)) {
output_file <- file.path(output_dir, paste0("document_", i, ".txt"))
writeLines(documents[[i]], output_file)
}
cat("Files created:", length(documents), "\n")
system("brew install tesseract")
system("brew install xpdf")
system("xcode-select --install")
system("brew install libtiff")
system("brew install ghostscript")
system("brew install imagemagick")
system("pdftotext /Users/robwells/Code/CompText_Jour/code/split_file/kemi.PDF kemi2.txt")
```{r}
system("pdftotext /Users/robwells/Code/CompText_Jour/code/split_file/kemi.PDF kemi2.txt")
system("pdftotext /Users/robwells/Code/CompText_Jour/code/split_file/kemi.PDF ../split_file/kemi3.txt")
system("pdftotext /Users/robwells/Code/CompText_Jour/code/split_file/kemi.PDF ../code/split_file/kemi3.txt")
library(tidyverse)
library(pdftools)
text <- pdf_text("../code/split_file/kemi.PDF")
writeLines(text, "../code/split_file/kemi4.txt")
text
# Step 1: Read the entire text file into R
file_path <- "../CompText_Jour/code/split_file/kemi4.txt"
text_data <- readLines(file_path)
# Step 1: Read the entire text file into R
file_path <- "/CompText_Jour/code/split_file/kemi4.txt"
text_data <- readLines(file_path)
# Step 1: Read the entire text file into R
file_path <- "Code/CompText_Jour/code/split_file/kemi4.txt"
text_data <- readLines(file_path)
# Step 1: Read the entire text file into R
file_path <- "/Code/CompText_Jour/code/split_file/kemi4.txt"
text_data <- readLines(file_path)
# Step 1: Read the entire text file into R
file_path <- "/Users/robwells/Code/CompText_Jour/code/split_file/kemi4.txt"
text_data <- readLines(file_path)
# Step 2: Combine lines into one single string
text_combined <- paste(text_data, collapse = "\n")
# Step 3: Split the text by the "End of Document" phrase
documents <- strsplit(text_combined, "End of Document")[[1]]
# Step 4: Write each section to a new file
output_dir <- "../CompText_Jour/code/split_file/"
for (i in seq_along(documents)) {
output_file <- file.path(output_dir, paste0("test2_document_", i, ".txt"))
writeLines(documents[[i]], output_file)
}
# Step 1: Read the entire text file into R
file_path <- "/Users/robwells/Code/CompText_Jour/code/split_file/kemi4.txt"
text_data <- readLines(file_path)
# Step 2: Combine lines into one single string
text_combined <- paste(text_data, collapse = "\n")
# Step 3: Split the text by the "End of Document" phrase
documents <- strsplit(text_combined, "End of Document")[[1]]
# Step 4: Write each section to a new file
output_dir <- "/CompText_Jour/code/split_file/"
for (i in seq_along(documents)) {
output_file <- file.path(output_dir, paste0("test2_document_", i, ".txt"))
writeLines(documents[[i]], output_file)
}
# Step 1: Read the entire text file into R
file_path <- "/Users/robwells/Code/CompText_Jour/code/split_file/kemi4.txt"
text_data <- readLines(file_path)
# Step 2: Combine lines into one single string
text_combined <- paste(text_data, collapse = "\n")
# Step 3: Split the text by the "End of Document" phrase
documents <- strsplit(text_combined, "End of Document")[[1]]
# Step 4: Write each section to a new file
output_dir <- "Code/CompText_Jour/code/split_file/"
for (i in seq_along(documents)) {
output_file <- file.path(output_dir, paste0("test2_document_", i, ".txt"))
writeLines(documents[[i]], output_file)
}
# Step 1: Read the entire text file into R
file_path <- "/Users/robwells/Code/CompText_Jour/code/split_file/kemi4.txt"
text_data <- readLines(file_path)
# Step 2: Combine lines into one single string
text_combined <- paste(text_data, collapse = "\n")
# Step 3: Split the text by the "End of Document" phrase
documents <- strsplit(text_combined, "End of Document")[[1]]
# Step 4: Write each section to a new file
output_dir <- "../Code/CompText_Jour/code/split_file/"
for (i in seq_along(documents)) {
output_file <- file.path(output_dir, paste0("test2_document_", i, ".txt"))
writeLines(documents[[i]], output_file)
}
# Step 1: Read the entire text file into R
file_path <- "/Users/robwells/Code/CompText_Jour/code/split_file/kemi4.txt"
text_data <- readLines(file_path)
# Step 2: Combine lines into one single string
text_combined <- paste(text_data, collapse = "\n")
# Step 3: Split the text by the "End of Document" phrase
documents <- strsplit(text_combined, "End of Document")[[1]]
# Step 4: Write each section to a new file
output_dir <- "/robwells/Code/CompText_Jour/code/split_file/"
for (i in seq_along(documents)) {
output_file <- file.path(output_dir, paste0("test2_document_", i, ".txt"))
writeLines(documents[[i]], output_file)
}
# Step 1: Read the entire text file into R
file_path <- "/Users/robwells/Code/CompText_Jour/code/split_file/kemi4.txt"
text_data <- readLines(file_path)
# Step 2: Combine lines into one single string
text_combined <- paste(text_data, collapse = "\n")
# Step 3: Split the text by the "End of Document" phrase
documents <- strsplit(text_combined, "End of Document")[[1]]
# Step 4: Write each section to a new file
output_dir <- "/Users/robwells/Code/CompText_Jour/code/split_file/"
for (i in seq_along(documents)) {
output_file <- file.path(output_dir, paste0("test2_document_", i, ".txt"))
writeLines(documents[[i]], output_file)
}
cat("Files created:", length(documents), "\n")
mob <- read.csv("https://github.com/wellsdata/CompText_Jour/raw/main/data/mob_analysis_data.csv")
View(mob)
mob %>%
group_by(Year) %>%
count(Year) %>%
slice_max(n, 15)
mob %>%
group_by(Year) %>%
count(Year) %>%
slice_max(n = 15)
mob %>%
group_by(Year) %>%
count(Year)
mob %>%
group_by(Year) %>%
count(Year) %>%
arrange(desc(n)) %>%
slice_max(n = 15)
mob %>%
group_by(Year) %>%
count(Year) %>%
order_by(n) %>%
slice_max(n = 15)
mob %>%
group_by(Year) %>%
summarize(count = n()) %>%
slice_max(order_by = count, n = 15)
mob %>%
group_by(Year) %>%
summarize(count = n()) %>%
slice_max(order_by = count, n = 5)
mob %>%
group_by(keyword) %>%
summarize(count = n()) %>%
slice_max(order_by = count, n = 5)
mob %>%
group_by(keyword) %>%
summarize(count = n())
mob %>%
group_by(keyword) %>%
summarize(count = n()) %>%
arrange(desc(count))
#Set working directory to .../data_journalism_class/04_labs/lab_04/pre_lab_04
baltcity_income <- read.csv("assets/data/baltcity_income_clean.csv") %>%
as.data.frame()
getwd()
glimpse(baltcity_income)
baltcity_income %>%
group_by(Neighborhood) %>%
summarise(
count_tracts = n()
)
baltcity_income %>%
group_by(Neighborhood) %>%
summarise(
count_tracts = n()
) %>%
arrange(desc(count_tracts))
baltcity_income %>%
summarise(
count_tracts = n()
)
baltcity_income %>%
select(Neighborhood, x2010, x2016, x2020, Census) %>%
summarise(
count_tracts = n(),
x2020_median = median(x2020, na.rm=TRUE),
min_2020 = min(x2020, na.rm=TRUE),
max_2020 = max(x2020, na.rm=TRUE)
)
summary(baltcity_income$x2020)
baltcity_income %>%
#temp code - remove later
as.data.frame() %>%
select(Neighborhood, x2020) %>%
filter(x2020 ==13559)
baltcity_income %>%
select(Neighborhood, x2020) %>%
filter((x2020 ==13559) | (x2020==199531))
baltcity_income %>%
select(Neighborhood, x2020, Census) %>%
summarise(
count_tracts = n(),
x2020_avg = mean(x2020, na.rm=TRUE))
baltcity_income %>%
select(Neighborhood, x2020, Census) %>%
summarise(
count_tracts = n(),
min_2020 = min(x2020, na.rm=TRUE),
max_2020 = max(x2020, na.rm=TRUE))
baltcity_income %>%
select(Neighborhood, x2010, x2016, x2020, Census) %>%
summarise(
count_tracts = n(),
x2020_median = median(x2020, na.rm=TRUE),
x2020_avg = mean(x2020, na.rm=TRUE),
x2016_median = median(x2016, na.rm=TRUE),
x2016_avg = mean(x2016, na.rm=TRUE),
x2010_median = median(x2010, na.rm=TRUE),
x2010_avg = mean(x2010, na.rm=TRUE))
#loading 2020 and 2010 Baltimore City population by race
baltcity_race <- read_csv("assets/data/baltcity_race_8_13.csv") %>%
as.data.frame()
baltcity_race %>%
select(x2020_white, x2020_black) %>%
summarize(
white_total = sum(x2020_white, na.rm = TRUE),
black_total = sum(x2020_black, na.rm = TRUE)
)
View(baltcity_race)
baltcity_income %>%
#temp code - remove later
as.data.frame() %>%
select(Neighborhood, x2020) %>%
filter(x2020 >=64372)
baltcity_income %>%
#temp code - remove later
as.data.frame() %>%
select(Neighborhood, x2020) %>%
filter(x2020 >=64372) %>%
arrange(desc(x2020))
baltcity_income %>%
#temp code - remove later
as.data.frame() %>%
select(Neighborhood, x2020) %>%
filter(x2020 >=100000) %>%
arrange(desc(x2020))
baltcity_income %>%
select(Neighborhood, x2020) %>%
filter((x2020 ==35702) | (x2020==64372))
baltcity_income %>%
select(Neighborhood, x2020) %>%
filter((x2020 >=35702) | (x2020<=64372))
baltcity_income %>%
select(Neighborhood, x2020) %>%
filter((x2020 >=35702) & (x2020<=64372))
baltcity_income %>%
select(Neighborhood, x2020) %>%
filter((x2020 >=35702) & (x2020<=49875))
baltcity_race %>%
select(x2020_white, x2020_black) %>%
summarize(
asian_total = sum(x2020_asian, na.rm = TRUE),
hispanic_total = sum(x2020_hispanic, na.rm = TRUE),
pac_islander_total = sum(x2020_pac_islander, na.rm = TRUE)
)
baltcity_race %>%
select(x2020_asian, x2020_hispanic, x2020_pac_islander) %>%
summarize(
asian_total = sum(x2020_asian, na.rm = TRUE),
hispanic_total = sum(x2020_hispanic, na.rm = TRUE),
pac_islander_total = sum(x2020_pac_islander, na.rm = TRUE)
)
